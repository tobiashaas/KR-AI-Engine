# ğŸ§ª KRAI Document Analysis Testing

**Test-Dokumente analysieren und optimale Chunking-Strategien finden**

---

## ğŸš€ **QUICK START**

### **1. Test-Environment Setup:**
```bash
cd backend/
python setup_test_environment.py
```

### **2. Test-Dokument hochladen:**
```bash
# Kopiere dein Test-Dokument in den test_documents Ordner
cp /path/to/your/document.pdf test_documents/
```

### **3. Dokument analysieren:**
```bash
python test_document_analyzer.py test_documents/your_document.pdf
```

---

## ğŸ“‹ **WAS WIRD ANALYSIERT?**

### **ğŸ“„ Dokument-Struktur:**
- **DateigrÃ¶ÃŸe** und Seitenzahl
- **Text-Struktur** (Paragraphen, SÃ¤tze, WÃ¶rter)
- **Technische Begriffe** und HÃ¤ufigkeiten
- **Ãœberschriften** und Kapitel-Struktur
- **Bilder und Tabellen** (bei PDFs)

### **ğŸ§ª Chunking-Strategien getestet:**

#### **1. Simple Word Chunking**
- **Beschreibung:** Einfache Wort-basierte Aufteilung
- **Vorteil:** GleichmÃ¤ÃŸige Chunk-GrÃ¶ÃŸen
- **Nachteil:** Kann Kontext unterbrechen

#### **2. Sentence-Based Chunking**
- **Beschreibung:** Satz-bewusste Aufteilung
- **Vorteil:** BehÃ¤lt Satz-Kontext
- **Nachteil:** UnregelmÃ¤ÃŸige Chunk-GrÃ¶ÃŸen

#### **3. Paragraph-Based Chunking**
- **Beschreibung:** Absatz-bewusste Aufteilung
- **Vorteil:** BehÃ¤lt Absatz-Kontext
- **Nachteil:** Sehr groÃŸe oder kleine Chunks mÃ¶glich

#### **4. Semantic Chunking**
- **Beschreibung:** Semantisch-bewusste Aufteilung
- **Vorteil:** BehÃ¤lt Bedeutungs-Kontext
- **Nachteil:** Komplexer zu implementieren

#### **5. Structure-Based Chunking**
- **Beschreibung:** Dokument-Struktur-bewusste Aufteilung
- **Vorteil:** Folgt Kapitel/Abschnitt-Struktur
- **Nachteil:** Funktioniert nur bei strukturierten Dokumenten

---

## ğŸ“Š **ANALYSE-ERGEBNISSE**

### **Was wird gemessen:**
- **Chunk-Anzahl** pro Strategie
- **Durchschnittliche Chunk-GrÃ¶ÃŸe** (in WÃ¶rtern)
- **GrÃ¶ÃŸen-Verteilung** (klein/medium/groÃŸ)
- **Standardabweichung** der Chunk-GrÃ¶ÃŸen

### **Optimale Chunk-GrÃ¶ÃŸe:**
- **Klein:** < 500 WÃ¶rter (zu klein fÃ¼r Kontext)
- **Medium:** 500-1500 WÃ¶rter (optimal)
- **GroÃŸ:** > 1500 WÃ¶rter (zu groÃŸ fÃ¼r Verarbeitung)

---

## ğŸ¯ **DOKUMENT-TYP ERKENNUNG**

### **Automatische Erkennung von:**
- **Service Manual** - ReparaturhandbÃ¼cher
- **Parts Catalog** - Ersatzteilkataloge
- **Technical Bulletin** - Technische Mitteilungen
- **CPMD Database** - HP-spezifische Begleithefte

### **Erkennungs-Merkmale:**
- **Keywords** im Text
- **Dateiname-Patterns**
- **Dokument-Struktur**
- **HÃ¤ufigkeit technischer Begriffe**

---

## ğŸ“ **TEST-DATEIEN STRUKTUR**

```
backend/
â”œâ”€â”€ test_documents/           # Hier deine Test-Dokumente
â”œâ”€â”€ analysis_reports/         # Generierte Analyse-Berichte
â”œâ”€â”€ logs/                     # Log-Dateien
â”œâ”€â”€ test_document_analyzer.py # Haupt-Analyse-Tool
â”œâ”€â”€ setup_test_environment.py # Environment Setup
â””â”€â”€ README_TESTING.md         # Diese Datei
```

---

## ğŸ”§ **KONFIGURATION ANPASSEN**

### **Chunk-GrÃ¶ÃŸen anpassen:**
```python
# In test_document_analyzer.py
def _simple_word_chunking(self, text: str, chunk_size: int = 1000, overlap: int = 200):
    # chunk_size: Ziel-GrÃ¶ÃŸe in WÃ¶rtern
    # overlap: Ãœberlappung zwischen Chunks
```

### **Neue Chunking-Strategien hinzufÃ¼gen:**
```python
# Neue Strategie in self.chunking_strategies hinzufÃ¼gen
'my_custom_strategy': self._my_custom_chunking
```

---

## ğŸ“Š **BEISPIEL-ERGEBNISSE**

### **Typische Ergebnisse fÃ¼r Service Manuals:**
```
ğŸ“„ DOCUMENT ANALYSIS SUMMARY
============================================================
ğŸ“ File: HP_LaserJet_4000_Service_Manual.pdf
ğŸ“ Size: 45.2 MB
ğŸ“ Words: 125,430
ğŸ“„ Pages: 234
ğŸ·ï¸  Type: service_manual (confidence: 0.89)

ğŸ§ª CHUNKING STRATEGIES TESTED:
  â€¢ simple_word_chunking: 126 chunks, avg 995 words
  â€¢ sentence_based: 98 chunks, avg 1280 words
  â€¢ paragraph_based: 67 chunks, avg 1872 words
  â€¢ structure_based: 45 chunks, avg 2787 words

ğŸ¯ RECOMMENDATION:
  Best strategy: sentence_based
  â€¢ Strategy 'sentence_based' provides optimal chunk distribution
  â€¢ Average chunk size: 1280 words
  â€¢ Total chunks: 98
```

---

## ğŸš¨ **TROUBLESHOOTING**

### **HÃ¤ufige Probleme:**

#### **1. "File not found" Error:**
```bash
# Stelle sicher, dass die Datei im richtigen Pfad ist
ls test_documents/
```

#### **2. "NLTK data not found" Error:**
```bash
# Setup-Script erneut ausfÃ¼hren
python setup_test_environment.py
```

#### **3. "PyMuPDF import error":**
```bash
# PyMuPDF installieren
pip install PyMuPDF
```

#### **4. GroÃŸe PDF-Dateien (600MB+):**
- **Teste zuerst mit kleineren Dateien**
- **ErhÃ¶he Memory-Limit falls nÃ¶tig**
- **Verwende asynchrone Verarbeitung**

---

## ğŸ’¡ **TIPS FÃœR BESTE ERGEBNISSE**

### **Test-Dokumente auswÃ¤hlen:**
1. **Verschiedene GrÃ¶ÃŸen** testen (1MB, 10MB, 100MB+)
2. **Verschiedene Typen** testen (Service Manual, Parts Catalog, Bulletin)
3. **Verschiedene QualitÃ¤ten** testen (gescannt, digital, gemischt)

### **Chunking-Strategien optimieren:**
1. **Starte mit sentence_based** fÃ¼r die meisten Dokumente
2. **Verwende structure_based** fÃ¼r gut strukturierte Manuals
3. **Kombiniere Strategien** fÃ¼r komplexe Dokumente

### **Performance optimieren:**
1. **Teste mit kleinen Dokumenten** zuerst
2. **Verwende asynchrone Verarbeitung** fÃ¼r groÃŸe Dateien
3. **Caching implementieren** fÃ¼r wiederholte Analysen

---

## ğŸ¯ **NÃ„CHSTE SCHRITTE**

Nach der Analyse:
1. **Optimale Chunking-Strategie** identifizieren
2. **Chunk-GrÃ¶ÃŸen** fÃ¼r verschiedene Dokumenttypen festlegen
3. **Contextual Chunking** implementieren
4. **Production Document Processor** entwickeln
5. **Vision AI** fÃ¼r technische Zeichnungen integrieren

---

**ğŸ§ª Happy Testing! Lass uns die optimale Chunking-Strategie finden!**
